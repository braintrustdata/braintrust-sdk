interactions:
- request:
    body: '{"contents": [{"parts": [{"text": "What is the weather like in Paris, France?"}],
      "role": "user"}], "tools": [{"functionDeclarations": [{"description": "Get the
      current weather for a location.\n\nArgs:\n    location: The city and state,
      e.g. San Francisco, CA\n    unit: The unit of temperature (celsius or fahrenheit)",
      "name": "get_weather", "parameters": {"properties": {"location": {"type": "STRING"},
      "unit": {"default": "celsius", "type": "STRING"}}, "required": ["location"],
      "type": "OBJECT"}}]}], "generationConfig": {"maxOutputTokens": 500}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '551'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - google-genai-sdk/1.41.0 gl-python/3.13.3
      x-goog-api-client:
      - google-genai-sdk/1.41.0 gl-python/3.13.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:streamGenerateContent?alt=sse
  response:
    body:
      string: "data: {\"candidates\": [{\"content\": {\"parts\": [{\"functionCall\":
        {\"name\": \"get_weather\",\"args\": {\"location\": \"Paris, France\"}}}],\"role\":
        \"model\"},\"finishReason\": \"STOP\"}],\"usageMetadata\": {\"promptTokenCount\":
        64,\"candidatesTokenCount\": 7,\"totalTokenCount\": 71,\"promptTokensDetails\":
        [{\"modality\": \"TEXT\",\"tokenCount\": 64}],\"candidatesTokensDetails\":
        [{\"modality\": \"TEXT\",\"tokenCount\": 7}]},\"modelVersion\": \"gemini-2.0-flash-001\",\"responseId\":
        \"CKXiaLvRF-eh3NoP5O6p-AU\"}\r\n\r\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Disposition:
      - attachment
      Content-Type:
      - text/event-stream
      Date:
      - Sun, 05 Oct 2025 17:04:08 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=519
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
- request:
    body: '{"contents": [{"parts": [{"text": "What is the weather like in Paris, France?"}],
      "role": "user"}, {"parts": [{"functionCall": {"args": {"location": "Paris, France"},
      "name": "get_weather"}}], "role": "model"}, {"parts": [{"functionResponse":
      {"name": "get_weather", "response": {"result": "22 degrees celsius and sunny
      in Paris, France"}}}], "role": "user"}], "tools": [{"functionDeclarations":
      [{"description": "Get the current weather for a location.\n\nArgs:\n    location:
      The city and state, e.g. San Francisco, CA\n    unit: The unit of temperature
      (celsius or fahrenheit)", "name": "get_weather", "parameters": {"properties":
      {"location": {"type": "STRING"}, "unit": {"default": "celsius", "type": "STRING"}},
      "required": ["location"], "type": "OBJECT"}}]}], "generationConfig": {"maxOutputTokens":
      500}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '812'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - google-genai-sdk/1.41.0 gl-python/3.13.3
      x-goog-api-client:
      - google-genai-sdk/1.41.0 gl-python/3.13.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:streamGenerateContent?alt=sse
  response:
    body:
      string: "data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"It\"}],\"role\":
        \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 145,\"totalTokenCount\":
        145,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 145}]},\"modelVersion\":
        \"gemini-2.0-flash-001\",\"responseId\": \"CKXiaKqeOc3-698PnKuguA0\"}\r\n\r\ndata:
        {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" is 22 degrees celsius
        and sunny in Paris, France.\\n\"}],\"role\": \"model\"},\"finishReason\":
        \"STOP\"}],\"usageMetadata\": {\"promptTokenCount\": 85,\"candidatesTokenCount\":
        15,\"totalTokenCount\": 100,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\":
        85}],\"candidatesTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\":
        15}]},\"modelVersion\": \"gemini-2.0-flash-001\",\"responseId\": \"CKXiaKqeOc3-698PnKuguA0\"}\r\n\r\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Disposition:
      - attachment
      Content-Type:
      - text/event-stream
      Date:
      - Sun, 05 Oct 2025 17:04:09 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=343
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
version: 1
